---
layout: single
title:  'Scikitlearn CountVectorizer/TfidfVectorizer'
excerpt: "Scikitlearn CountVectorizer/TfidfVectorizer를 이용한 전처리"
toc: true
toc_sticky: true
categories:
  - Python
tags:
  - Scikitlearn
  - Programming
comments : true
header:
  image: '/assets/images/IMG_0001.JPG'
---
{:toc}

# 소개
CountVectorizer, TfidfVectorizer메서드는 자연어 처리 분석을 할 때, 비교와 해석에 필요한 형태로 변형시켜 처리가능한 특징을 추출하는 전처리 과정입니다.
보통 이러한 특징 추출은 문자열을 수치형 벡터로 변환하는 방법을 통해 이루어집니다.
이 두 메서드는 아래 방법으로 호출합니다.

    from sklearn.feature_extractrion.text import CountVectorizer, TfidfVectorizer
    
    
이때 괄호 안에 여러 파라미터를 이용하여 좀더 세부적으로 전처리과정을 제어 할 수 있습니다.

# CountVectorizer
주어진 텍스트 데이터에서 단위별 등장 횟수를 세어 수치로 벡터화 하는 것입니다.
단위는 문서, 문장, 단어 등으로 가장 많이 사용되는 것은 단어 단위로 세는 것입니다.
먼저 단어 사전 벡터를 만들고, 문장을 확인하여 단어사전 벡터에 각 자리에 해당하는 단어별로 횟수를 셉니다.

예를들어
[I, You, am, are, an, a, annoying, orange, Apple]
이라는 단어 사전이 있을 때
I am an annoying orange. 라는 문장을 보면
[1, 0, 1, 0, 1, 0, 1, 1, 0]
이라는 벡터로 변환이 됩니다.

먼저 여러 텍스트가 포함된 데이터로부터 단어를 추출하여 단어사전을 만듭니다.

    count_vectorizer=CountVectorizer()
    count_vectorizer.fit('원하는 텍스트 데이터')
    print(count_vectorizer.vocabulary)
    
이렇게 CountVectorizer객체를 만들고 원하는 텍스트 데이터를 넣어주면 단어사전 벡터를 만듭니다.
이 때 특별한 의미가 없는 단어인데도 자주 사용되는 단어가 모델의 성능에 영향을 줄 수 있습니다.
이를 해결하기 위해 TF-IDF가 만들어졌습니다.

# TfidfVectorizer
TF-IDF는 특정 단위(문서, 문장 등)에서는 많이 등장하지만, 다른 단위에서는 적게 사용되는가? 즉 분별력 있는 특징인가를 평가하는 요소입니다.
* TF는 특정 단어가 하나의 데이터에서 등장하는 횟수
* DF는 특정 단어가 여러 데이터에서 등장하는 횟수
* IDF는 1/DF
즉 TF-IDF는 TF와 IDF의 곱으로 분별력을 표시할 수 있습니다. 사용법은 CountVectorizer와 같습니다.

    tfidf_vectorizer=CountVectorizer()
    tfidf_vectorizer.fit('원하는 텍스트 데이터')
    print(tfidf_vectorizer.vocabulary)
